<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">



<title type="text">CDSLab Recipes - A repository for all sorts of problems with solutions</title>
<generator uri="https://github.com/shahmoradi/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="https://www.cdslab.org/recipes/feed.xml" />
<link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/" />
<updated>2023-04-16T00:41:32-05:00</updated>
<id>https://www.cdslab.org/recipes/</id>
<author>
  <name>Amir Shahmoradi</name>
  <uri>https://www.cdslab.org/recipes/</uri>
  <email>shahmoradi@utexas.edu</email>
</author>


<entry>
  <title type="html"><![CDATA[IEEE-storage convention for real numbers]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/digital-storage-real-number/digital/digital-storage-real-number"/>
  <id>https://www.cdslab.org/recipes/programming/digital-storage-real-number/digital/digital-storage-real-number</id>
  <published>2023-02-25T00:00:00-06:00</published>
  <updated>2023-02-25T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#integer" term="integer" /><category scheme="https://www.cdslab.org/recipes/tags/#memory" term="memory" /><category scheme="https://www.cdslab.org/recipes/tags/#IEEE" term="IEEE" /><category scheme="https://www.cdslab.org/recipes/tags/#storage" term="storage" /><category scheme="https://www.cdslab.org/recipes/tags/#real" term="real" /><category scheme="https://www.cdslab.org/recipes/tags/#float" term="float" /><category scheme="https://www.cdslab.org/recipes/tags/#real32" term="real32" /><category scheme="https://www.cdslab.org/recipes/tags/#real64" term="real64" /><category scheme="https://www.cdslab.org/recipes/tags/#real128" term="real128" />
  <content type="html">
  
    
&lt;p&gt;Recall that computers can only store discrete values in memory.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;What does this imply for the storage of real (floating-point) numbers in computers?&lt;/li&gt;
  &lt;li&gt;Now consider the IEEE-storage convention for real numbers in computers for &lt;code&gt;real32&lt;/code&gt;, &lt;code&gt;real64&lt;/code&gt;, and &lt;code&gt;real128&lt;/code&gt; bit storage formats as illustrated below.
    &lt;figure&gt;&lt;img src=&quot;../real32.png&quot; width=&quot;100%&quot; /&gt;&lt;/figure&gt;
    &lt;figure&gt;&lt;img src=&quot;../real64.png&quot; width=&quot;100%&quot; /&gt;&lt;/figure&gt;
    &lt;figure&gt;&lt;img src=&quot;../real128.png&quot; width=&quot;100%&quot; /&gt;&lt;/figure&gt;
    &lt;p&gt;Compute how many real numbers each of the above formats can represent.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;How many of these numbers are in the range $[0, 1)$ for each storage convention?&lt;/li&gt;
  &lt;li&gt;What are the minimum and maximum possible representable real values in these conventions?&lt;/li&gt;
  &lt;li&gt;Is there a way to represent numbers that are smaller than the minimum representable real numbers in these conventions?&lt;/li&gt;
&lt;/ol&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/digital-storage-real-number/digital/digital-storage-real-number&quot;&gt;IEEE-storage convention for real numbers&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on February 25, 2023.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Intel OneAPI C/C++/Fortran Compiler Installation]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/intel-oneapi-c-cpp-fortran-compiler-installation/intel-oneapi-c-cpp-fortran-compiler-installation"/>
  <id>https://www.cdslab.org/recipes/programming/intel-oneapi-c-cpp-fortran-compiler-installation/intel-oneapi-c-cpp-fortran-compiler-installation</id>
  <published>2023-01-01T00:00:00-06:00</published>
  <updated>2020-01-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#Intel%20Parallel%20Studio" term="Intel Parallel Studio" /><category scheme="https://www.cdslab.org/recipes/tags/#Microsoft%20Visual%20Studio" term="Microsoft Visual Studio" /><category scheme="https://www.cdslab.org/recipes/tags/#Windows" term="Windows" /><category scheme="https://www.cdslab.org/recipes/tags/#installation" term="installation" /><category scheme="https://www.cdslab.org/recipes/tags/#Fortran" term="Fortran" /><category scheme="https://www.cdslab.org/recipes/tags/#C" term="C" /><category scheme="https://www.cdslab.org/recipes/tags/#C++" term="C++" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;How can I install the Intel OneAPI C/C++/Fortran Compiler on Windows, Linux, or macOS?&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-top:2rem;margin-bottom:2rem;&quot;&gt;

    &lt;a href=&quot;#solution&quot; style=&quot;display:inline-block;&quot;&gt;
        &lt;h2 id=&quot;solution&quot; style=&quot;color:blue;&quot;&gt;
            Solution
        &lt;/h2&gt;
    &lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;The Intel OneAPI HPC toolkit provides a wide variety of High-Performance numerical libraries and tools, most importantly, the Intel Fortran and C/C++ compilers.&lt;br /&gt;
However, its installation, particularly, on Windows systems can be a bit tricky.&lt;/p&gt;

&lt;p&gt;Here are the &lt;strong&gt;steps required to take to properly install the Intel OneAPI compilers on Linux/macOS/Windows&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If you are a Linux/macOS user move on to step 2.&lt;br /&gt;
If you are a &lt;strong&gt;Windows&lt;/strong&gt; user,
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;Download&lt;/strong&gt; a recent version of &lt;strong&gt;Microsoft Visual Studio (MSVS) Community edition&lt;/strong&gt; installer 
which is &lt;a href=&quot;https://visualstudio.microsoft.com/vs/community&quot; target=&quot;_blank&quot;&gt;available free of charge&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Run the Microsoft Visual Studio installer&lt;/strong&gt;.&lt;br /&gt;
Once you see the following prompt window, make sure you &lt;strong&gt;select at least the C++ components to install on your system&lt;/strong&gt; (if you do not want all of the components).&lt;br /&gt;
This component selection is essential for successful installation of Intel OneAPI components and compilers,
        &lt;figure&gt;
    &lt;img src=&quot;community-page-installer.png&quot; /&gt;
&lt;/figure&gt;
        &lt;p&gt;Once the installation is complete, you may need to reboot your system.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Download Intel OneAPI Base Toolkit&lt;/strong&gt; from its &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html&quot; target=&quot;_blank&quot;&gt;dedicated website&lt;/a&gt;. &lt;br /&gt;
Follow the installation instructions provided by Intel to install the Base Toolkit.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Download Intel OneAPI HPC Toolkit&lt;/strong&gt; from its &lt;a href=&quot;https://www.intel.com/content/www/us/en/developer/tools/oneapi/hpc-toolkit-download.html&quot; target=&quot;_blank&quot;&gt;dedicated website&lt;/a&gt;. &lt;br /&gt;
Follow the installation instructions provided by Intel to install the HPC Toolkit.&lt;br /&gt;
This component contains all Intel products relevant to scientific computing, parallel computing, and C/C++/Fortran compilers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Your installation is complete&lt;/strong&gt; (you may need a reboot again).
    &lt;ol&gt;
      &lt;li&gt;If you are on &lt;strong&gt;Windows&lt;/strong&gt;,
        &lt;ol&gt;
          &lt;li&gt;You can now access intel compilers and tools from within the Microsoft Visual Studio application.&lt;/li&gt;
          &lt;li&gt;You can also use the &lt;strong&gt;use Intel’s provided Windows command-line environment (CMD)&lt;/strong&gt; that comes with all the Intel OneAPI.&lt;br /&gt;
This environment contains all paths to Intel applications predefined &lt;strong&gt;to help build your applications on the command line, much like a Linux environment&lt;/strong&gt;.&lt;br /&gt;
In the long run, you will likely find the command line much more convenient than the GUI interface that the Microsoft Visual Studio application offers.
            &lt;figure&gt;
    &lt;img src=&quot;intelCMD.png&quot; /&gt;
&lt;/figure&gt;
          &lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;On all platforms, whether Windows or Unix, you can now open the relevant terminal (Intel CMD on Windows and Bash/dash/zsh/… terminal on Linux/macOS) 
to test whether the Intel compilers have been correctly installed by typing &lt;code&gt;ifx&lt;/code&gt; to invoke the Intel Fortran compiler or &lt;code&gt;icl&lt;/code&gt; to invoke the Intel C++ compiler, 
The following snapshot demonstrates the usage on Windows CMD terminal,
        &lt;figure&gt;
    &lt;img src=&quot;compilerTest.png&quot; /&gt;
&lt;/figure&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/intel-oneapi-c-cpp-fortran-compiler-installation/intel-oneapi-c-cpp-fortran-compiler-installation&quot;&gt;Intel OneAPI C/C++/Fortran Compiler Installation&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on January 01, 2023.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Logic NAND and NOR]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/logic-nand-nor/logic/logic-nand-nor"/>
  <id>https://www.cdslab.org/recipes/programming/logic-nand-nor/logic/logic-nand-nor</id>
  <published>2022-11-01T00:00:00-05:00</published>
  <updated>2020-11-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#plausibility" term="plausibility" /><category scheme="https://www.cdslab.org/recipes/tags/#deduction" term="deduction" /><category scheme="https://www.cdslab.org/recipes/tags/#reasoning" term="reasoning" /><category scheme="https://www.cdslab.org/recipes/tags/#logic" term="logic" /><category scheme="https://www.cdslab.org/recipes/tags/#boolean" term="boolean" /><category scheme="https://www.cdslab.org/recipes/tags/#implication" term="implication" />
  <content type="html">
  
    
&lt;p&gt;Recall the definitions of NAND and NOR from our lecture notes. Show that,&lt;/p&gt;

\[\overline{(A \uparrow A) \downarrow (B \uparrow B)} \equiv (\overline{A} \downarrow \overline{A}) \uparrow (\overline{B} \downarrow \overline{B}) ~.\]


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/logic-nand-nor/logic/logic-nand-nor&quot;&gt;Logic NAND and NOR&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 01, 2022.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Logical implication in terms of logic functions]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/logic-functions-implication/logic-functions-implication"/>
  <id>https://www.cdslab.org/recipes/programming/logic-functions-implication/logic-functions-implication</id>
  <published>2022-10-21T00:00:00-05:00</published>
  <updated>2020-10-21T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#plausibility" term="plausibility" /><category scheme="https://www.cdslab.org/recipes/tags/#deduction" term="deduction" /><category scheme="https://www.cdslab.org/recipes/tags/#reasoning" term="reasoning" /><category scheme="https://www.cdslab.org/recipes/tags/#logic" term="logic" /><category scheme="https://www.cdslab.org/recipes/tags/#boolean" term="boolean" /><category scheme="https://www.cdslab.org/recipes/tags/#implication" term="implication" />
  <content type="html">
  
    
&lt;p&gt;Consider the following logic functions,&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;basisTruthTable.png&quot; width=&quot;350&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;Show that,&lt;/p&gt;

\[f_1(A, B) + f_3(A, B) + f_4(A, B)\]

&lt;p&gt;is equivalent to logical implication $A \Rightarrow B$.&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/logic-functions-implication/logic-functions-implication&quot;&gt;Logical implication in terms of logic functions&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on October 21, 2022.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Version-control: Setting up Git Software and GitHub Account]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/vcs-git-github-setup/vcs-git-github-setup"/>
  <id>https://www.cdslab.org/recipes/programming/vcs-git-github-setup/vcs-git-github-setup</id>
  <published>2022-09-13T00:00:00-05:00</published>
  <updated>2022-09-13T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#VCS" term="VCS" /><category scheme="https://www.cdslab.org/recipes/tags/#git" term="git" /><category scheme="https://www.cdslab.org/recipes/tags/#GitHub" term="GitHub" /><category scheme="https://www.cdslab.org/recipes/tags/#version%20control%20system" term="version control system" /><category scheme="https://www.cdslab.org/recipes/tags/#project" term="project" /><category scheme="https://www.cdslab.org/recipes/tags/#markdown" term="markdown" /><category scheme="https://www.cdslab.org/recipes/tags/#git%20branch" term="git branch" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:4rem;margin-bottom:1rem;&quot;&gt;
    
    
    
    &lt;figure&gt;
        &lt;a href=&quot;#git&quot; id=&quot;git&quot;&gt;
            &lt;img src=&quot;https://www.cdslab.org/recipes/images/Git.png&quot; width=&quot;75px&quot; /&gt;
        &lt;/a&gt;
        &lt;figcaption&gt;
            &lt;a href=&quot;https://en.wikipedia.org/wiki/Git&quot; target=&quot;_blank&quot;&gt;
                Git
            &lt;/a&gt;
        &lt;/figcaption&gt;
    &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This exercise guides you through the steps needed to take to properly install and minimally use the git software and the Git Bash terminal on your system.&lt;br /&gt;
By the end of this exercise, you will be able to initialize an empty git project anywhere in your computer, or initialize a project on GitHub and clone it to your system.&lt;br /&gt;
&lt;strong&gt;Guidelines.&lt;/strong&gt; Use the following references for operations in a (Git) Bash terminal.&lt;br /&gt;
    - &lt;a href=&quot;https://www.cdslab.org/python/notes/preliminary-foundations/version-control-system/linuxRef.pdf&quot; target=&quot;_blank&quot;&gt;Linux Bash command reference&lt;/a&gt;
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Only Windows users&lt;/strong&gt;. Before installing the Git software, I highly recommend you to download and install the most recent version of &lt;a href=&quot;https://notepad-plus-plus.org/downloads/&quot; target=&quot;_blank&quot;&gt;Nodepad++ text editor&lt;/a&gt; on your system, if you do not have it already.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Git installation&lt;/strong&gt;. Visit the &lt;a href=&quot;https://git-scm.com/downloads&quot; target=&quot;_blank&quot;&gt;Git downloads website&lt;/a&gt; and download the most recent version of the git software to install on your system.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Only Windows users&lt;/strong&gt;. During the installation, the git software may ask you to link your Notepad++ software with git. If given this option, choose it.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interacting with Git&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;Depending on your operating system,
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;On Windows systems&lt;/strong&gt;,
            &lt;ol&gt;
              &lt;li&gt;press the Windows key + &lt;code&gt;E&lt;/code&gt; to open a Windows explorer.&lt;br /&gt;
&lt;img src=&quot;explorer-key-shortcut.jpg&quot; alt=&quot;explorer-key-shortcut.jpg&quot; /&gt;&lt;/li&gt;
              &lt;li&gt;Then, navigate to the directory &lt;code&gt;C:\Users\account&lt;/code&gt;, where you have to replace &lt;code&gt;account&lt;/code&gt; with your Windows account name.&lt;/li&gt;
              &lt;li&gt;Now right-click on an empty region of the Windows explorer, you should see a menu like the following.&lt;br /&gt;
&lt;img src=&quot;git.bash.here.png&quot; alt=&quot;git.bash.here.png&quot; /&gt;&lt;br /&gt;
Click on “Git Bash Here” to open a Git Bash session. You should see a Bash session opened like the following screen shot,&lt;br /&gt;
&lt;img src=&quot;git.bash.png&quot; alt=&quot;git.bash.png&quot; /&gt;&lt;br /&gt;
What is &lt;strong&gt;Git Bash&lt;/strong&gt;? Git Bash is simply a &lt;a href=&quot;https://en.wikipedia.org/wiki/Bash_(Unix_shell)&quot; target=&quot;_blank&quot;&gt;Bash terminal&lt;/a&gt; that is tailored for Git usage on Windows.&lt;br /&gt;
The Linux and macOS operating systems have Bash-compatible terminals (shells) that allow interaction with the operating system.&lt;br /&gt;
The Git software was originally built as a Linux application that natively used the Linux terminals for interaction.&lt;br /&gt;
However, Windows system is not fully compatible with Linux terminals and does not have native Linux-compatible terminals.&lt;br /&gt;
Therefore, the Git developers decided to ship the Git software with a dedicated Bash terminal for use on Windows systems,
so that Windows users also get the same feeling as Linux and macOS users when dealing with Git software.&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;On Linux / macOS systems&lt;/strong&gt;.
            &lt;ol&gt;
              &lt;li&gt;Simply search for &lt;strong&gt;terminal&lt;/strong&gt; in the search box of your operating system and open a terminal.&lt;/li&gt;
              &lt;li&gt;Then type &lt;code&gt;cd ~&lt;/code&gt; and press enter. This will take you to &lt;strong&gt;home directory&lt;/strong&gt; of your system.&lt;/li&gt;
              &lt;li&gt;Then type &lt;code&gt;open .&lt;/code&gt; in your terminal and press enter to open a &lt;strong&gt;macOS finder&lt;/strong&gt; in the same location as your home folder.&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Now, within your terminal (whether Git Bash or Linux/macOS terminal), type &lt;code&gt;pwd&lt;/code&gt; and press enter.&lt;br /&gt;
&lt;strong&gt;Why?&lt;/strong&gt; This Bash command displays the current working directory where you are.&lt;br /&gt;
It should print the path to the home directory of your system, because you are already in the home directory.&lt;/li&gt;
      &lt;li&gt;Now type &lt;code&gt;ls -a&lt;/code&gt; and press enter.&lt;br /&gt;
&lt;strong&gt;Why?&lt;/strong&gt; This Bash command will display a list of all files and folders in the home directory of your computer.&lt;br /&gt;
The &lt;code&gt;-a&lt;/code&gt; flag requests the Bash terminal to show all files (&lt;strong&gt;including hidden files&lt;/strong&gt;).&lt;br /&gt;
Note that any file or folder whose name begins with a &lt;code&gt;.&lt;/code&gt; is automatically hidden from your view.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Creating your first Git project.&lt;/strong&gt;&lt;br /&gt;
There are two ways to create git projects,
    &lt;ol&gt;
      &lt;li&gt;Creating a git project on your local system.
        &lt;ul&gt;
          &lt;li&gt;Now type &lt;code&gt;mkdir git&lt;/code&gt; and press enter.&lt;br /&gt;
&lt;strong&gt;Why?&lt;/strong&gt; This Bash command will create a new folder named &lt;code&gt;git&lt;/code&gt; within the current directory of your Bash session (which is already your home directory).&lt;br /&gt;
Although you can use any place in your computer to store your Git projects, it is good practice and much easier to keep them all in one place (the &lt;code&gt;git&lt;/code&gt; folder you just created).
            &lt;blockquote&gt;
              &lt;p&gt;Some of you may have already created a &lt;code&gt;git&lt;/code&gt; folder in your home directory. &lt;br /&gt;
  In such a case, the command &lt;code&gt;mkdir git&lt;/code&gt; will lead to an error because the folder already exists.&lt;br /&gt;
  Do not panic, ignore the error message and move on to the next step below.&lt;/p&gt;
            &lt;/blockquote&gt;
          &lt;/li&gt;
          &lt;li&gt;Now type &lt;code&gt;ls -l&lt;/code&gt; again and press enter.&lt;br /&gt;
&lt;strong&gt;Why?&lt;/strong&gt; If you have successfully created the new folder &lt;code&gt;git&lt;/code&gt; in your current directory, this command will show you the new folder in the listing it displays.&lt;br /&gt;
If you cannot find it, you need to reach out to me to identify the roots of the problem.&lt;/li&gt;
          &lt;li&gt;Now type &lt;code&gt;cd git&lt;/code&gt; and press enter.&lt;br /&gt;
&lt;strong&gt;Why?&lt;/strong&gt; The &lt;code&gt;cd&lt;/code&gt; Bash command stands for &lt;strong&gt;Change Directory&lt;/strong&gt;. Therefore, &lt;code&gt;cd git&lt;/code&gt; will change your current working directory from your home directory to the subdirectory &lt;code&gt;git&lt;/code&gt;.&lt;/li&gt;
          &lt;li&gt;Now, we want to create a new git project in this folder. Let’s say the name of the project is &lt;code&gt;test&lt;/code&gt;.&lt;/li&gt;
          &lt;li&gt;First, we will have to create a &lt;code&gt;test&lt;/code&gt; folder where we will store all files and materials related to the &lt;code&gt;test&lt;/code&gt; git project. Type the following in the terminal and press enter.
            &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;cd test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;This command will create a &lt;code&gt;test&lt;/code&gt; subfolder in your &lt;code&gt;git&lt;/code&gt; folder and then will change the current directory to wihtin the &lt;code&gt;test&lt;/code&gt; subfolder.&lt;br /&gt;
The &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; simply means &lt;strong&gt;and&lt;/strong&gt;: Make directory &lt;code&gt;test&lt;/code&gt; &lt;strong&gt;and&lt;/strong&gt; change directory to &lt;code&gt;test&lt;/code&gt;.&lt;/p&gt;
          &lt;/li&gt;
          &lt;li&gt;This is where we want to host our git test project. To initialize an empty Git project here, type the following git command in the terminal,
            &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Done.&lt;/strong&gt; You have successfully created an empty test Git project on your computer.&lt;/li&gt;
          &lt;li&gt;Each and every Git project is always associated with a &lt;code&gt;.git&lt;/code&gt; subfolder in the same location where your store your project on your system.&lt;br /&gt;
To ensure you have successfully initiated a Git project, type &lt;code&gt;ls -a&lt;/code&gt; in your terminal and press enter.&lt;br /&gt;
This should display a list among which there is &lt;code&gt;.git&lt;/code&gt;.&lt;br /&gt;
If you do not see this hidden folder in the list displayed, your &lt;code&gt;test&lt;/code&gt; folder is &lt;strong&gt;not&lt;/strong&gt; a git project yet!&lt;/li&gt;
          &lt;li&gt;Of course, your Git project is still empty. But you can now put anything you like in it and make it part of your project.&lt;br /&gt;
For example, we can add an empty text file to it by typing,
            &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;touch &lt;/span&gt;README.md
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;in the Bash terminal and pressing enter.&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Creating a git project on a server and cloning the project on your local system.&lt;br /&gt;
This is the easier way of initializing projects and sharing them with other Team members in the project.&lt;br /&gt;
In the follow-up exercises, we will learn how to initialize Git projects using &lt;a href=&quot;https://github.com/&quot; target=&quot;_blank&quot;&gt;GitHub&lt;/a&gt; as the git server.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/vcs-git-github-setup/vcs-git-github-setup&quot;&gt;Version-control: Setting up Git Software and GitHub Account&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on September 13, 2022.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[A naive implementation of Kmedoids clustering]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/clustering-naive-kmedioid-implementation/clustering-naive-kmedioid-implementation"/>
  <id>https://www.cdslab.org/recipes/programming/clustering-naive-kmedioid-implementation/clustering-naive-kmedioid-implementation</id>
  <published>2021-12-01T00:00:00-06:00</published>
  <updated>2021-12-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#MATLAB" term="MATLAB" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#matplotlib" term="matplotlib" /><category scheme="https://www.cdslab.org/recipes/tags/#scikit-learn" term="scikit-learn" /><category scheme="https://www.cdslab.org/recipes/tags/#clustering" term="clustering" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#kmeans" term="kmeans" /><category scheme="https://www.cdslab.org/recipes/tags/#Kmedoids" term="Kmedoids" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;The K-medoids is a classical partitioning technique of clustering that splits the data set of $n$ objects into $k$ clusters, where the number $k$ of clusters is assumed to be known a priori. Unlike the K-means algorithm however, &lt;strong&gt;the K-medoids algorithm chooses points within the dataset as the centers of the clusters&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A naive implementation of the K-medoids algorithm is similar to the K-means algorithm and requires the following steps,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Select the initial medoids randomly (that is, select $k$ points from the dataset randomly as the cluster centers).&lt;/li&gt;
  &lt;li&gt;Iterate while the cost decreases:
    &lt;ol&gt;
      &lt;li&gt;In each cluster, make the point that minimizes the sum of distances within the cluster the medoid.&lt;/li&gt;
      &lt;li&gt;Reassign each point to the cluster defined by the closest medoid determined in the previous step.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Write a function in Python, MATLAB, or your preferred language to cluster an input dataset using the naive K-medoids method.&lt;br /&gt;
Test the functionality of your algorithm with &lt;a href=&quot;https://www.cdslab.orghttps://www.cdslab.org/recipes/programming/clustering-kmeans-implementation/points.txt&quot; target=&quot;_blank&quot;&gt;this example dataset&lt;/a&gt; for 6 clusters.&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/clustering-naive-kmedioid-implementation/clustering-naive-kmedioid-implementation&quot;&gt;A naive implementation of Kmedoids clustering&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on December 01, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Online comparison of the Kmeans clustering algorithm with DBSCAN]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/clustering-kmeans-vs-dbscan-online/clustering-kmeans-vs-dbscan-online"/>
  <id>https://www.cdslab.org/recipes/programming/clustering-kmeans-vs-dbscan-online/clustering-kmeans-vs-dbscan-online</id>
  <published>2021-12-01T00:00:00-06:00</published>
  <updated>2021-12-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#clustering" term="clustering" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#scatter%20plot" term="scatter plot" /><category scheme="https://www.cdslab.org/recipes/tags/#kmeans" term="kmeans" /><category scheme="https://www.cdslab.org/recipes/tags/#DBSCAN" term="DBSCAN" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;On &lt;a href=&quot;https://www.naftaliharris.com/blog/visualizing-k-means-clustering/&quot; target=&quot;_blank&quot;&gt;this website&lt;/a&gt;, you will find an online simulator of the Kmeans clustering technique.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Visit this page and choose the first choice stating &lt;strong&gt;I’ll Chooose&lt;/strong&gt;. You will be taken to a new page.&lt;/li&gt;
  &lt;li&gt;On this new page, choose &lt;strong&gt;Smiley Face&lt;/strong&gt;. Then, you will be taken to a another page where you see a set of points like a smiley face.&lt;/li&gt;
  &lt;li&gt;You will notice that you have the choice of adding (specifying) as many cluster centers as you like. Using mouse clicks, specify (add) four cluster centers on your best guess for the cluster centers.&lt;/li&gt;
  &lt;li&gt;Then, press &lt;strong&gt;Go!&lt;/strong&gt; and then continue updating &lt;strong&gt;Centroids&lt;/strong&gt; (cluster centers) until the cluster do not change visibly anymore (convergence to a set of clusters has occurred).&lt;/li&gt;
  &lt;li&gt;Is the final set of clusters that you get satisfying?&lt;/li&gt;
  &lt;li&gt;Take a screenshot of the clusters that you get and submit it with your homework.&lt;/li&gt;
  &lt;li&gt;Repeat this procedure with a new random set of cluster centers.&lt;/li&gt;
  &lt;li&gt;Do the resulting clusters look the same as you got before? Why?&lt;/li&gt;
  &lt;li&gt;Take a screenshot of the clusters that you get and submit it with your homework.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, visit &lt;a href=&quot;https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/&quot; target=&quot;_blank&quot;&gt;this website&lt;/a&gt; and choose the same option &lt;strong&gt;Smiley Face&lt;/strong&gt; as before to perform DBSCAN clustering on the same &lt;strong&gt;Smiley Face&lt;/strong&gt; data. Adjust the parameters such that the two eyes, mouth, and the face-circle each become separate clusters. Why is the DBSCAN clustering so much more successful than the Kmeans? Take a screenshot of the clustering result to submit with your homework.&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/clustering-kmeans-vs-dbscan-online/clustering-kmeans-vs-dbscan-online&quot;&gt;Online comparison of the Kmeans clustering algorithm with DBSCAN&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on December 01, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Online experimentation with DBSCAN clustering technique]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/clustering-dbscan-online/clustering-dbscan-online"/>
  <id>https://www.cdslab.org/recipes/programming/clustering-dbscan-online/clustering-dbscan-online</id>
  <published>2021-12-01T00:00:00-06:00</published>
  <updated>2021-12-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#clustering" term="clustering" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#scatter%20plot" term="scatter plot" /><category scheme="https://www.cdslab.org/recipes/tags/#DBSCAN" term="DBSCAN" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;On &lt;a href=&quot;https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/&quot; target=&quot;_blank&quot;&gt;this website&lt;/a&gt;, you will find an online simulator of the DBSCAN clustering technique. Visit this page and choose the first dataset option named &lt;strong&gt;Uniform&lt;/strong&gt;. Recall from our lecture notes that the DBSCAN method has two free adjustable parameters that you need to set prior to clustering.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;What are the two free parameters of the DBSCAN clustering technique?&lt;/li&gt;
  &lt;li&gt;Choose a set of parameters for DBSCAN on this page for the uniform dataset such that all points are partitioned a single cluster. Is this set of parameters unique to achieve the same clustering result? If not, provide another example set of parameters?&lt;/li&gt;
  &lt;li&gt;Now, choose another set of parameters such that there is at least one outlier (noise) point left at the end of clustering that does not belong to any cluster.&lt;/li&gt;
&lt;/ol&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/clustering-dbscan-online/clustering-dbscan-online&quot;&gt;Online experimentation with DBSCAN clustering technique&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on December 01, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Kmeans clustering - an implementation]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/clustering-kmeans-implementation/clustering-kmeans-implementation"/>
  <id>https://www.cdslab.org/recipes/programming/clustering-kmeans-implementation/clustering-kmeans-implementation</id>
  <published>2021-11-29T00:00:00-06:00</published>
  <updated>2019-11-21T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#numpy" term="numpy" /><category scheme="https://www.cdslab.org/recipes/tags/#matplotlib" term="matplotlib" /><category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#scikit-learn" term="scikit-learn" /><category scheme="https://www.cdslab.org/recipes/tags/#clustering" term="clustering" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#scatter%20plot" term="scatter plot" /><category scheme="https://www.cdslab.org/recipes/tags/#kmeans" term="kmeans" /><category scheme="https://www.cdslab.org/recipes/tags/#kmeans++" term="kmeans++" /><category scheme="https://www.cdslab.org/recipes/tags/#figure" term="figure" /><category scheme="https://www.cdslab.org/recipes/tags/#random%20number" term="random number" /><category scheme="https://www.cdslab.org/recipes/tags/#pandas" term="pandas" /><category scheme="https://www.cdslab.org/recipes/tags/#read_csv" term="read_csv" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Consider this dataset &lt;a href=&quot;points.txt&quot; target=&quot;_blank&quot;&gt;points.txt&lt;/a&gt;. 
Write a script that reads this dataset and plots the second column of the dataset versus the first column as the following,&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;points.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Now write another script that applies Kmeans clustering technique to this data set and plot the 
resulting clusters for a range of input number of clusters. Here is an example plot for a cluster count of 6.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;clusters6.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Make an Elbow plot with the inertia of the clusterings you have done with various cluster counts.&lt;/p&gt;

&lt;p&gt;Now, write a new algorithm implementing the Kmeans method.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The function that you write must take a two dimensional data as input and the number of clusters to find.&lt;/li&gt;
  &lt;li&gt;Then the function randomly initializes the centers of the clusters.&lt;/li&gt;
  &lt;li&gt;Then it computes the distances of each point from each cluster center.&lt;/li&gt;
  &lt;li&gt;Then it assigns each point to its nearest cluster center.&lt;/li&gt;
  &lt;li&gt;Based on the members identified for each cluster, the function computes the new cluster centers as the averages of their member points.&lt;/li&gt;
  &lt;li&gt;Then it compares the new centers with the old centers and if no center has changed by more than a certain threshold, it returns the memberships and the cluster centers as the clustering result. Otherwise, if at least one center has change beyond the arbitrary threshold that you have set (or the user passes to your function), then it repeats all of the above tasks from 3 to the end, until convergence occurs.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Verify the functionality of your implementation with the external package that you originally used to perform Kmeans clustering.&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/clustering-kmeans-implementation/clustering-kmeans-implementation&quot;&gt;Kmeans clustering - an implementation&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 29, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Kmeans clustering: Determining the cluster number using the Elbow method]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/clustering-kmeans-customers/clustering-kmeans-customers"/>
  <id>https://www.cdslab.org/recipes/programming/clustering-kmeans-customers/clustering-kmeans-customers</id>
  <published>2021-11-21T00:00:00-06:00</published>
  <updated>2019-11-21T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#numpy" term="numpy" /><category scheme="https://www.cdslab.org/recipes/tags/#matplotlib" term="matplotlib" /><category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#scikit-learn" term="scikit-learn" /><category scheme="https://www.cdslab.org/recipes/tags/#clustering" term="clustering" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#scatter%20plot" term="scatter plot" /><category scheme="https://www.cdslab.org/recipes/tags/#kmeans" term="kmeans" /><category scheme="https://www.cdslab.org/recipes/tags/#kmeans++" term="kmeans++" /><category scheme="https://www.cdslab.org/recipes/tags/#figure" term="figure" /><category scheme="https://www.cdslab.org/recipes/tags/#random%20number" term="random number" /><category scheme="https://www.cdslab.org/recipes/tags/#pandas" term="pandas" /><category scheme="https://www.cdslab.org/recipes/tags/#read_csv" term="read_csv" /><category scheme="https://www.cdslab.org/recipes/tags/#Elbow%20method" term="Elbow method" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Consider this dataset &lt;a href=&quot;customers.csv&quot; target=&quot;_blank&quot;&gt;customers.csv&lt;/a&gt; of a Mall’s customers containing the details of customers in a mall. Our aim is to cluster the customers based on the relevant features “annual income” and “spending score”. Write a script that reads this dataset and plots the relevant attributes of the dataset against each other like the following,&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;customers.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Then, the script performs K-means clustering on the two selected attributes of data with a range of number of clusters. Then use the Elbow method to find the optimal number of clusters for the customers in this dataset.&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/clustering-kmeans-customers/clustering-kmeans-customers&quot;&gt;Kmeans clustering: Determining the cluster number using the Elbow method&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 21, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Regression: Predicting the distribution of the a dataset subjected to a smooth censorship (sample incompleteness)]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/regression-erf-censored-gaussian-data/regression-erf-censored-gaussian-data"/>
  <id>https://www.cdslab.org/recipes/programming/regression-erf-censored-gaussian-data/regression-erf-censored-gaussian-data</id>
  <published>2021-11-19T00:00:00-06:00</published>
  <updated>2021-11-19T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#MATLAB" term="MATLAB" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#Gaussian" term="Gaussian" /><category scheme="https://www.cdslab.org/recipes/tags/#Error%20Function" term="Error Function" /><category scheme="https://www.cdslab.org/recipes/tags/#Cumulative%20Distribution%20Function" term="Cumulative Distribution Function" /><category scheme="https://www.cdslab.org/recipes/tags/#integration" term="integration" /><category scheme="https://www.cdslab.org/recipes/tags/#CDF" term="CDF" /><category scheme="https://www.cdslab.org/recipes/tags/#regression" term="regression" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution" term="distribution" /><category scheme="https://www.cdslab.org/recipes/tags/#censored" term="censored" /><category scheme="https://www.cdslab.org/recipes/tags/#sample%20incompleteness" term="sample incompleteness" /><category scheme="https://www.cdslab.org/recipes/tags/#Normal%20distribution" term="Normal distribution" /><category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#line" term="line" /><category scheme="https://www.cdslab.org/recipes/tags/#figure" term="figure" /><category scheme="https://www.cdslab.org/recipes/tags/#random%20number" term="random number" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution%20function" term="distribution function" /><category scheme="https://www.cdslab.org/recipes/tags/#probability%20density%20function" term="probability density function" /><category scheme="https://www.cdslab.org/recipes/tags/#PDF" term="PDF" /><category scheme="https://www.cdslab.org/recipes/tags/#probability" term="probability" /><category scheme="https://www.cdslab.org/recipes/tags/#objective%20function" term="objective function" /><category scheme="https://www.cdslab.org/recipes/tags/#maximum%20likelihood%20method" term="maximum likelihood method" /><category scheme="https://www.cdslab.org/recipes/tags/#Monte%20Carlo" term="Monte Carlo" /><category scheme="https://www.cdslab.org/recipes/tags/#Markov%20Chain" term="Markov Chain" /><category scheme="https://www.cdslab.org/recipes/tags/#MCMC" term="MCMC" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaMonte" term="ParaMonte" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaDRAM" term="ParaDRAM" /><category scheme="https://www.cdslab.org/recipes/tags/#uncertainty%20quantification" term="uncertainty quantification" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Supposed we have observed a dataset of events with one attribute &lt;code&gt;variable&lt;/code&gt; in this file: &lt;a href=&quot;data.csv&quot; target=&quot;_blank&quot;&gt;data.csv&lt;/a&gt;. Plotting these points would yield a blue-colored histogram like the following plot,&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;data.png&quot; width=&quot;900&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Unlike the previous problems where the censorship was due to a sharp cutoff on a Gaussian dataset, the smooth cutoff in this problem is due to the following Gaussian model mixed with and inverted Gaussian CDF,&lt;/p&gt;

\[\pi( x | \mu_G, \sigma_G, \mu_C, \sigma_C) \propto \mathcal{N}(x | \mu_G, \sigma_G) \times \frac{1}{2} \Big[ 1 + \text{erf}\Big(\frac{\mu_C-x}{\sigma_C\sqrt{2}}\Big) \Big] ~,\]

&lt;p&gt;where $\mu_G, \sigma_G$ are the mean and standard deviation parameters of the Gaussian distribution and $\mu_G, \sigma_G$ are the unknown parameters of the Gaussian CDF smooth cutoff on this dataset.&lt;/p&gt;

&lt;p&gt;Now our goal is to constrain the four unknown parameters of the above model using the maximum likelihood method. You can use the &lt;a href=&quot;https://www.cdslab.org/paramonte/&quot; target=&quot;_blank&quot;&gt;ParaMonte library&lt;/a&gt; in Python or in MATLAB to explore the resulting log-likelihood function. In such s case, make sure you start your MCMC exploration by a good set of initial parameter values, such that the MCMC sampler can correctly explore the parameter-space without getting lost. You can get help from &lt;a href=&quot;https://www.cdslab.orghttps://www.cdslab.org/recipes/programming/regression-censored-gaussian-data/regression-censored-gaussian-data&quot; target=&quot;_blank&quot;&gt;another relevant problem here&lt;/a&gt;.&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/regression-erf-censored-gaussian-data/regression-erf-censored-gaussian-data&quot;&gt;Regression: Predicting the distribution of the a dataset subjected to a smooth censorship (sample incompleteness)&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 19, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Puzzle: Matchstick Wrong Equation]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/puzzle-matchstick-equation/puzzle-matchstick-equation"/>
  <id>https://www.cdslab.org/recipes/programming/puzzle-matchstick-equation/puzzle-matchstick-equation</id>
  <published>2021-11-15T00:00:00-06:00</published>
  <updated>2021-10-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#matchstick" term="matchstick" /><category scheme="https://www.cdslab.org/recipes/tags/#equation" term="equation" /><category scheme="https://www.cdslab.org/recipes/tags/#puzzle" term="puzzle" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Move just one matchstick in the following equation to make it hold.&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&quot;matchstick_equation.png&quot; /&gt;
&lt;/figure&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/puzzle-matchstick-equation/puzzle-matchstick-equation&quot;&gt;Puzzle: Matchstick Wrong Equation&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 15, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Puzzle: How many living creatures are in the pond]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/puzzle-how-many-animals-in-pond/puzzle-how-many-animals-in-pond"/>
  <id>https://www.cdslab.org/recipes/programming/puzzle-how-many-animals-in-pond/puzzle-how-many-animals-in-pond</id>
  <published>2021-11-15T00:00:00-06:00</published>
  <updated>2021-10-01T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#matchstick" term="matchstick" /><category scheme="https://www.cdslab.org/recipes/tags/#equation" term="equation" /><category scheme="https://www.cdslab.org/recipes/tags/#puzzle" term="puzzle" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;How many living creatures can you identify in this figure? (&lt;strong&gt;Hint:&lt;/strong&gt; There are two).&lt;/p&gt;
&lt;figure&gt;
    &lt;img src=&quot;animals-in-pond.png&quot; /&gt;
&lt;/figure&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/puzzle-how-many-animals-in-pond/puzzle-how-many-animals-in-pond&quot;&gt;Puzzle: How many living creatures are in the pond&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 15, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Regression: Predicting the global land temperature of Earth in 2050 from the past data: Choosing the best model]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/regression-predicting-future-global-land-temperature-excel/regression-predicting-future-global-land-temperature-excel"/>
  <id>https://www.cdslab.org/recipes/programming/regression-predicting-future-global-land-temperature-excel/regression-predicting-future-global-land-temperature-excel</id>
  <published>2021-11-11T00:00:00-06:00</published>
  <updated>2021-11-11T00:00:00-06:00</updated>
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#Excel" term="Excel" /><category scheme="https://www.cdslab.org/recipes/tags/#regression" term="regression" /><category scheme="https://www.cdslab.org/recipes/tags/#global" term="global" /><category scheme="https://www.cdslab.org/recipes/tags/#warming" term="warming" /><category scheme="https://www.cdslab.org/recipes/tags/#climate" term="climate" /><category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#line" term="line" /><category scheme="https://www.cdslab.org/recipes/tags/#figure" term="figure" /><category scheme="https://www.cdslab.org/recipes/tags/#random%20number" term="random number" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution%20function" term="distribution function" /><category scheme="https://www.cdslab.org/recipes/tags/#probability%20density%20function" term="probability density function" /><category scheme="https://www.cdslab.org/recipes/tags/#PDF" term="PDF" /><category scheme="https://www.cdslab.org/recipes/tags/#probability" term="probability" /><category scheme="https://www.cdslab.org/recipes/tags/#objective%20function" term="objective function" /><category scheme="https://www.cdslab.org/recipes/tags/#least%20squares%20method" term="least squares method" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Consider this dataset, &lt;a href=&quot;1880_2020.csv&quot; target=&quot;_blank&quot;&gt;1880_2020.csv&lt;/a&gt;, which contains the global land and ocean temperature anomalies of the earth from January 1880 to June 2020 at every month. As stated in the file, temperatures are in Degrees Celsius and reported as anomalies relative to the average global land temperature of the Earth between in the year 1950.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First, use Microsoft Excel software to plot the temperature anomalies reported in this dataset. You can divide the &lt;code&gt;Year&lt;/code&gt; column of data by $100$ to obtain real years.&lt;/li&gt;
  &lt;li&gt;Fit a linear regression to temperature anomaly like the following illustration in Excel and obtain the linear regression equation. Then use the equation to predict the temperature of Earth in 2050.
    &lt;figure&gt;
    &lt;img src=&quot;linear.png&quot; /&gt;
&lt;/figure&gt;
  &lt;/li&gt;
  &lt;li&gt;Fit a quadratic (Polynomial of degree two) regression to temperature anomaly like the following illustration in Excel and obtain the quadratic regression equation. Then use the equation to predict the temperature of Earth in 2050.
    &lt;figure&gt;
    &lt;img src=&quot;quadratic.png&quot; /&gt;
&lt;/figure&gt;
  &lt;/li&gt;
  &lt;li&gt;Which one of the mathematical models that you have fir to data is a better representation of reality? Which one predicts more temperature increase in the near future?&lt;/li&gt;
&lt;/ol&gt;

  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/regression-predicting-future-global-land-temperature-excel/regression-predicting-future-global-land-temperature-excel&quot;&gt;Regression: Predicting the global land temperature of Earth in 2050 from the past data: Choosing the best model&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 11, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Regression: Estimating the parameters of a linear model for a Normally-distributed sample]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/regression-linear-gaussian/regression-linear-gaussian"/>
  <id>https://www.cdslab.org/recipes/programming/regression-linear-gaussian/regression-linear-gaussian</id>
  <published>2021-11-05T00:00:00-05:00</published>
  <updated>2021-11-05T00:00:00-05:00</updated>
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#MATLAB" term="MATLAB" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#linear" term="linear" /><category scheme="https://www.cdslab.org/recipes/tags/#regression" term="regression" /><category scheme="https://www.cdslab.org/recipes/tags/#linear" term="linear" /><category scheme="https://www.cdslab.org/recipes/tags/#Gaussian" term="Gaussian" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution" term="distribution" /><category scheme="https://www.cdslab.org/recipes/tags/#Normal%20distribution" term="Normal distribution" /><category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#line" term="line" /><category scheme="https://www.cdslab.org/recipes/tags/#figure" term="figure" /><category scheme="https://www.cdslab.org/recipes/tags/#random%20number" term="random number" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution%20function" term="distribution function" /><category scheme="https://www.cdslab.org/recipes/tags/#probability%20density%20function" term="probability density function" /><category scheme="https://www.cdslab.org/recipes/tags/#PDF" term="PDF" /><category scheme="https://www.cdslab.org/recipes/tags/#probability" term="probability" /><category scheme="https://www.cdslab.org/recipes/tags/#objective%20function" term="objective function" /><category scheme="https://www.cdslab.org/recipes/tags/#maximum%20likelihood%20method" term="maximum likelihood method" /><category scheme="https://www.cdslab.org/recipes/tags/#Monte%20Carlo" term="Monte Carlo" /><category scheme="https://www.cdslab.org/recipes/tags/#Markov%20Chain" term="Markov Chain" /><category scheme="https://www.cdslab.org/recipes/tags/#MCMC" term="MCMC" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaMonte" term="ParaMonte" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaDRAM" term="ParaDRAM" /><category scheme="https://www.cdslab.org/recipes/tags/#uncertainty%20quantification" term="uncertainty quantification" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Supposed we have observed a dataset comprised of events with one attribute as in this file: &lt;a href=&quot;z.csv&quot; target=&quot;_blank&quot;&gt;z.csv&lt;/a&gt;. Plotting these points would yield a histogram like the following plot,&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;z.png&quot; width=&quot;900&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now our goal is to form a hypothesis about this dataset, that is, a hypothesis about the distribution of the events in the above plot. Just by looking at the observed distribution, we can form a relatively good hypothesis about the distribution of the data: This dataset is likely very well fit by a Normal distribution.&lt;/p&gt;

&lt;p&gt;Now, use the maximum likelihood method to infer the two unknown parameters of the Normal distribution that best fits the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hint:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First read the data using Pandas library.&lt;/li&gt;
  &lt;li&gt;Write a function/class that takes the data as input and has two methods, &lt;code&gt;getLogProb(data,avg,std)&lt;/code&gt; and &lt;code&gt;getLogLike(param)&lt;/code&gt;. The former computes the log-probability of observing the input dataset &lt;code&gt;data&lt;/code&gt; given the parameters of the model (the Normal average &lt;code&gt;avg&lt;/code&gt; and the Normal standard deviation &lt;code&gt;std&lt;/code&gt;). The latter method takes a set of parameters as a vector containing the average of the Normal distribution (&lt;code&gt;avg&lt;/code&gt;) and the natural-logarithm of the standard deviation of the Normal distribution &lt;code&gt;log(std)&lt;/code&gt;. Given these two parameters, &lt;code&gt;getLogLike(param)&lt;/code&gt; sums over the log-probabilities returned by &lt;code&gt;getLogProb(data,avg,std)&lt;/code&gt; to compute the log-likelihood and returns it as the output.&lt;/li&gt;
  &lt;li&gt;You can use &lt;code&gt;scipy.optimize.fmin&lt;/code&gt; to perform the maximization of log-likelihood to obtain the best-fit parameters. Once done with the minimization (of negative log-likelihood), report the best-fit parameters on the display.&lt;/li&gt;
  &lt;li&gt;Now, consider the following more complicated problem with this data &lt;a href=&quot;xy.csv&quot; target=&quot;_blank&quot;&gt;xy.csv&lt;/a&gt;. Visualizing this dataset gives us the following plot.
    &lt;figure&gt;
    &lt;img src=&quot;xy.png&quot; width=&quot;900&quot; /&gt;
&lt;/figure&gt;
    &lt;p&gt;&lt;br /&gt;
As you may have guessed, the only difference between this dataset and the previous one is that the random variable in this case depends on another deterministic variable $x$, most-likely, in the following manner, $y \sim \mathcal{N}(\mu = b \times x + a, \sigma)$. In other words, the data ($y$) still comes from a Normal distribution, but its mean depends on the corresponding value of $x$. Therefore, in this problem, we have three unknown parameters to optimize for: $(\sigma, a, b)$. Now, implement the maximum likelihood method for this problem by revising your answer to the previous problem in the above and make a plot of the best-fit line to the data, like the following.&lt;/p&gt;
    &lt;figure&gt;
    &lt;img src=&quot;xy-fit-linear.png&quot; width=&quot;900&quot; /&gt;
&lt;/figure&gt;
    &lt;p&gt;&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/regression-linear-gaussian/regression-linear-gaussian&quot;&gt;Regression: Estimating the parameters of a linear model for a Normally-distributed sample&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on November 05, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Regression: Estimating the parameters of a Normally-distributed sample]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/regression-gaussian-data/regression-gaussian-data"/>
  <id>https://www.cdslab.org/recipes/programming/regression-gaussian-data/regression-gaussian-data</id>
  <published>2021-10-28T00:00:00-05:00</published>
  <updated>2021-10-28T00:00:00-05:00</updated>
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#MATLAB" term="MATLAB" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#linear" term="linear" /><category scheme="https://www.cdslab.org/recipes/tags/#regression" term="regression" /><category scheme="https://www.cdslab.org/recipes/tags/#Gaussian" term="Gaussian" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution" term="distribution" /><category scheme="https://www.cdslab.org/recipes/tags/#Normal%20distribution" term="Normal distribution" /><category scheme="https://www.cdslab.org/recipes/tags/#visualization" term="visualization" /><category scheme="https://www.cdslab.org/recipes/tags/#plot" term="plot" /><category scheme="https://www.cdslab.org/recipes/tags/#line" term="line" /><category scheme="https://www.cdslab.org/recipes/tags/#figure" term="figure" /><category scheme="https://www.cdslab.org/recipes/tags/#random%20number" term="random number" /><category scheme="https://www.cdslab.org/recipes/tags/#distribution%20function" term="distribution function" /><category scheme="https://www.cdslab.org/recipes/tags/#probability%20density%20function" term="probability density function" /><category scheme="https://www.cdslab.org/recipes/tags/#PDF" term="PDF" /><category scheme="https://www.cdslab.org/recipes/tags/#probability" term="probability" /><category scheme="https://www.cdslab.org/recipes/tags/#objective%20function" term="objective function" /><category scheme="https://www.cdslab.org/recipes/tags/#maximum%20likelihood%20method" term="maximum likelihood method" /><category scheme="https://www.cdslab.org/recipes/tags/#Monte%20Carlo" term="Monte Carlo" /><category scheme="https://www.cdslab.org/recipes/tags/#Markov%20Chain" term="Markov Chain" /><category scheme="https://www.cdslab.org/recipes/tags/#MCMC" term="MCMC" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaMonte" term="ParaMonte" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaDRAM" term="ParaDRAM" /><category scheme="https://www.cdslab.org/recipes/tags/#uncertainty%20quantification" term="uncertainty quantification" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Supposed we have observed a dataset comprised of $15027$ events with one attribute &lt;code&gt;variable&lt;/code&gt; in this file: &lt;a href=&quot;dataFull.csv&quot; target=&quot;_blank&quot;&gt;dataFull.csv&lt;/a&gt;. Plotting these points would yield a histogram like the following plot,&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;data.png&quot; width=&quot;900&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Now our goal is to form a hypothesis about this dataset, that is, a hypothesis about the distribution of the events in the above plot.&lt;/p&gt;

&lt;p&gt;To help you get started, we can first take the logarithm of this dataset to better understand the distribution of the attribute of the dataset and plot the transformed data,&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&quot;logdata.png&quot; width=&quot;900&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Just by looking at the observed (red) distribution, we can form a relatively good hypothesis about the distribution of the data: This dataset is likely very well fit by a log-normal distribution, that is, the log-transform of data is very well fit by a Normal distribution.&lt;/p&gt;

&lt;p&gt;Now, use the maximum likelihood method to infer the two unknown parameters of the corresponding Normal distribution that best fits the log-transformed data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hint:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First read the data using Pandas library, then log-transform data to make it look like a Normal distribution.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Write a class that takes the log-data as input and has two methods, &lt;code&gt;getLogProb(data,avg,std)&lt;/code&gt; and &lt;code&gt;getLogLike(param)&lt;/code&gt;. The former computes the log-probability of observing the input dataset &lt;code&gt;data&lt;/code&gt; given the parameters of the model (the Normal average &lt;code&gt;avg&lt;/code&gt; and the Normal standard deviation &lt;code&gt;std&lt;/code&gt;). The latter method takes a set of parameters as a vector containing the average of the Normal distribution (&lt;code&gt;avg&lt;/code&gt;) and the natural-logarithm of the standard deviation of the Normal distribution &lt;code&gt;log(std)&lt;/code&gt;. Given these two parameters, &lt;code&gt;getLogLike(param)&lt;/code&gt; sums over the log-probabilities returned by &lt;code&gt;getLogProb(data,avg,std)&lt;/code&gt; to compute the log-likelihood and returns it as the output.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;You can use &lt;code&gt;scipy.optimize.fmin&lt;/code&gt; to perform the maximization of log-likelihood to obtain the best-fit parameters. Once done with the minimization (of negative log-likelihood), report the best-fit parameters on the display.&lt;/li&gt;
&lt;/ol&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/regression-gaussian-data/regression-gaussian-data&quot;&gt;Regression: Estimating the parameters of a Normally-distributed sample&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on October 28, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Computing the cross-correlation of sin() and cos()]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/stat-crosscorr-sin-cos/stat-crosscorr-sin-cos"/>
  <id>https://www.cdslab.org/recipes/programming/stat-crosscorr-sin-cos/stat-crosscorr-sin-cos</id>
  <published>2021-10-20T00:00:00-05:00</published>
  <updated>2019-07-04T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#statistics" term="statistics" /><category scheme="https://www.cdslab.org/recipes/tags/#sample" term="sample" /><category scheme="https://www.cdslab.org/recipes/tags/#covariance" term="covariance" /><category scheme="https://www.cdslab.org/recipes/tags/#correlation" term="correlation" /><category scheme="https://www.cdslab.org/recipes/tags/#crosscorrelation" term="crosscorrelation" /><category scheme="https://www.cdslab.org/recipes/tags/#sin" term="sin" /><category scheme="https://www.cdslab.org/recipes/tags/#cos" term="cos" /><category scheme="https://www.cdslab.org/recipes/tags/#periodic" term="periodic" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Generate two arrays corresponding to the values of $\sin(x)$ and $\cos(x+\pi/2)$ functions in the range $[0, 10\pi]$. Make a plot of the resulting arrays like the following illustration.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;sin-cos.png&quot; alt=&quot;sin-cos&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now use an FFT package in the language of your choice to compute the cross-correlation between the two resulting arrays from $\sin()$ and $\cos()$. Plot the resulting cross-correlation to obtain an illustration like the following.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;sin-cos-ccf.png&quot; alt=&quot;sin-cos-ccf&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Explain the reason for the periodic behavior of the cross-correlation. Why does the periodic signal decay toward the tails?&lt;/p&gt;

&lt;p&gt;Now compute the autocorrelation of each of the arrays separately and plot the resulting autocorrelations to compare with the CCF between the two as computed in the above. Plot the resulting autocorrelations to obtain illustrations like the following,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;sin-sin-acf.png&quot; alt=&quot;sin-sin-acf&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;cos-cos-acf.png&quot; alt=&quot;cos-cos-acf&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Explain why the autocorrelations of &lt;code&gt;sin()&lt;/code&gt; and &lt;code&gt;cos()&lt;/code&gt; are similar to each other while they look different from the cross-correlation in the above. What can you do to make the cross-correlation of &lt;code&gt;sin-cos&lt;/code&gt; look like the autocorrelations of &lt;code&gt;sin-sin&lt;/code&gt; and &lt;code&gt;cos-cos&lt;/code&gt;?&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/stat-crosscorr-sin-cos/stat-crosscorr-sin-cos&quot;&gt;Computing the cross-correlation of sin() and cos()&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on October 20, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Computing the cross-correlation of two data attributes]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/stat-crosscorr/stat-crosscorr"/>
  <id>https://www.cdslab.org/recipes/programming/stat-crosscorr/stat-crosscorr</id>
  <published>2021-10-11T00:00:00-05:00</published>
  <updated>2019-07-04T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#statistics" term="statistics" /><category scheme="https://www.cdslab.org/recipes/tags/#sample" term="sample" /><category scheme="https://www.cdslab.org/recipes/tags/#covariance" term="covariance" /><category scheme="https://www.cdslab.org/recipes/tags/#correlation" term="correlation" /><category scheme="https://www.cdslab.org/recipes/tags/#crosscorrelation" term="crosscorrelation" /><category scheme="https://www.cdslab.org/recipes/tags/#warming" term="warming" /><category scheme="https://www.cdslab.org/recipes/tags/#CO2" term="CO2" /><category scheme="https://www.cdslab.org/recipes/tags/#carbon" term="carbon" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Consider &lt;a href=&quot;annual-co2-emissions-per-country.csv&quot; target=&quot;blank&quot;&gt;this dataset of carbon emissions history per country&lt;/a&gt;.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Make a visualization of the &lt;strong&gt;global&lt;/strong&gt; carbon emission data in the CSV file in the above by summing over the contributions of all countries per year to obtain an illustration like the following,&lt;br /&gt;
&lt;img src=&quot;globalEmissionsCO2.png&quot; alt=&quot;Global CO2 Emissions&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Now consider the contribution of individual countries in this &lt;a href=&quot;annual-co-emissions-by-region.csv&quot;&gt;&lt;em&gt;zero-filled&lt;/em&gt; CSV dataset&lt;/a&gt; and make a stacked plot of the countries over the years, like the following,&lt;br /&gt;
&lt;img src=&quot;regionEmissionsCO2.png&quot; alt=&quot;Region CO2 Emissions&quot; /&gt;&lt;br /&gt;
To do so, you will have to extract the data for the following regions from the CSV file and &lt;code&gt;matplotlib&lt;/code&gt; &lt;code&gt;stackplot&lt;/code&gt; in Python or some other similar package or function in your language of choice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Recall the &lt;a href=&quot;globalLandTempHist.txt&quot; target=&quot;blank&quot;&gt;globalLandTempHist.txt&lt;/a&gt; dataset that consists of the global land temperature of Earth over the past 300 years. Parse the contents of this file to generate the average annual temperature anomaly data. Then, extract the subset of CSV data from Step 2 in the above corresponding to the regional keyword &lt;code&gt;&quot;World&quot;&lt;/code&gt; in the &lt;code&gt;Entity&lt;/code&gt; column of data. Then, match the temperature anomaly data with the global CO2 emission data to generate a unified dataset. Then, write a function that computes the cross-correlation between the temperature anomaly and the global CO2 emissions. Use the definition of the correlation matrix that we have seen before to compute the cross-correlation.&lt;br /&gt;
Now, use an external library in the language of your choice to compute the autocorrelation using Fast-Fourier Transform (FFT). Within Python, you can use &lt;code&gt;correlate&lt;/code&gt; in SciPy package &lt;code&gt;from scipy.signal import correlate&lt;/code&gt; to compute the autocorrelation. To do so, you will have to first normalize the input data (the anomaly data) to its mean. Then you pass the data in syntax like the following,
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correlate&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;emissions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emissions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emissions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;emissions&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;full&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;Make a plot of this autocorrelation function (acf) and compare with what you have obtained from the slow version you have implemented.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/stat-crosscorr/stat-crosscorr&quot;&gt;Computing the cross-correlation of two data attributes&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on October 11, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Computing the autocorrelation of a dataset]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/stat-autocorr/stat-autocorr"/>
  <id>https://www.cdslab.org/recipes/programming/stat-autocorr/stat-autocorr</id>
  <published>2021-10-11T00:00:00-05:00</published>
  <updated>2019-07-04T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#statistics" term="statistics" /><category scheme="https://www.cdslab.org/recipes/tags/#sample" term="sample" /><category scheme="https://www.cdslab.org/recipes/tags/#covariance" term="covariance" /><category scheme="https://www.cdslab.org/recipes/tags/#correlation" term="correlation" /><category scheme="https://www.cdslab.org/recipes/tags/#autocorrelation" term="autocorrelation" /><category scheme="https://www.cdslab.org/recipes/tags/#warming" term="warming" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Recall the &lt;a href=&quot;globalLandTempHist.txt&quot; target=&quot;blank&quot;&gt;globalLandTempHist.txt&lt;/a&gt; dataset that consisted of the global land temperature of Earth over the past 300 years. 
Also recall that the autocorrelation of a time-series is defined as the correlation of a univariate dataset with itself, with some positive lag $\tau$.&lt;/p&gt;

&lt;p&gt;Use the definition of the correlation matrix that we have seen before to compute the autocorrelation of temperature anomaly of Earth starting from the first non-NAN value to the end, for all different possible lags. Make a plot of the autocorrelation vs. lag.&lt;/p&gt;

&lt;p&gt;Now, use an external library in the language of your choice to compute the autocorrelation using Fast-Fourier Transform (FFT). Within Python, you can use &lt;code&gt;correlate&lt;/code&gt; in SciPy package &lt;code&gt;from scipy.signal import correlate&lt;/code&gt; to compute the autocorrelation. To do so, you will have to first normalize the input data (the anomaly data) to its mean. Then you pass the data in syntax like the following,&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correlate&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anomalies&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;full&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Make a plot of this autocorrelation function (acf) and compare with what you have obtained from the slow version you have implemented. Here is an illustration of the average anomaly data per year and its autocorrelation function,&lt;br /&gt;
&lt;img src=&quot;globalTempAnomalies.png&quot; alt=&quot;globalTempAnomalies.png&quot; /&gt;
&lt;img src=&quot;globalTempAnomaliesACF.png&quot; alt=&quot;globalTempAnomaliesACF.png&quot; /&gt;&lt;/p&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/stat-autocorr/stat-autocorr&quot;&gt;Computing the autocorrelation of a dataset&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on October 11, 2021.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Computing and removing the autocorrelation of a dataset]]></title>
  
  <link rel="alternate" type="text/html" href="https://www.cdslab.org/recipes/programming/stat-autocorr-removal/stat-autocorr-removal"/>
  <id>https://www.cdslab.org/recipes/programming/stat-autocorr-removal/stat-autocorr-removal</id>
  <published>2021-10-11T00:00:00-05:00</published>
  <updated>2019-07-04T00:00:00-00:00</updated>
  
  <author>
    <name>Amir Shahmoradi</name>
    <uri>https://www.cdslab.org/recipes</uri>
    <email>shahmoradi@utexas.edu</email>
  </author>
  <category scheme="https://www.cdslab.org/recipes/tags/#statistics" term="statistics" /><category scheme="https://www.cdslab.org/recipes/tags/#sample" term="sample" /><category scheme="https://www.cdslab.org/recipes/tags/#covariance" term="covariance" /><category scheme="https://www.cdslab.org/recipes/tags/#correlation" term="correlation" /><category scheme="https://www.cdslab.org/recipes/tags/#autocorrelation" term="autocorrelation" /><category scheme="https://www.cdslab.org/recipes/tags/#warming" term="warming" /><category scheme="https://www.cdslab.org/recipes/tags/#Python" term="Python" /><category scheme="https://www.cdslab.org/recipes/tags/#ParaMonte" term="ParaMonte" /><category scheme="https://www.cdslab.org/recipes/tags/#MCMC" term="MCMC" /><category scheme="https://www.cdslab.org/recipes/tags/#Monte%20Carlo" term="Monte Carlo" />
  <content type="html">
  
    
&lt;div style=&quot;text-align:center;margin-top:3rem;margin-bottom:2rem;&quot;&gt;
    
        &lt;a href=&quot;#problem&quot; style=&quot;display:inline-block;&quot;&gt;
            &lt;h2 id=&quot;problem&quot; style=&quot;color:red;&quot;&gt;
                Problem
            &lt;/h2&gt;
        &lt;/a&gt;
    
&lt;/div&gt;

&lt;p&gt;Consider the following Banana function.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getLogFuncBanana&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvn&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.special&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logsumexp&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;NPAR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;                        &lt;span class=&quot;c1&quot;&gt;# sum(Banana,gaussian) normalization factor
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;normfac&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;                   &lt;span class=&quot;c1&quot;&gt;# sum(Banana,gaussian) normalization factor
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;lognormfac&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normfac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# sum(Banana,gaussian) normalization factor
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;# parameters of the Banana function
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;MeanB&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;           &lt;span class=&quot;c1&quot;&gt;# mean vector of Banana function
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;MeanG&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;3.5&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;           &lt;span class=&quot;c1&quot;&gt;# mean vector of Gaussian function
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;CovMatB&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.81&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newshape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NPAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NPAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Covariance matrix of Banana function
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;CovMatG&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newshape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NPAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NPAR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Covariance matrix of Gaussian function
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;LogProb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# transformed parameters that transform the Gaussian to the Banana function
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Gaussian function
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;LogProb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lognormfac&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logpdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MeanG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CovMatG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# logProbBanana
&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Do variable transformations for the Skewed-Gaussian (banana) function.
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Banana function
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;LogProb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mvn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logpdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointSkewed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MeanB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CovMatB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# logProbBanana
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;logsumexp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LogProb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We wish to generate random sample from the distribution function represented by this Python function. We do so via the ParaMonte library’s ParaDRAM MCMC sampler,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upgrade&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paramonte&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;paramonte&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;paradram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chainSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;runSampler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getLogFunc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getLogFuncBanana&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This sampler outputs an MCMC chain that we can subsequently visualize,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;notebook&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;readChain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;renabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Banana Function Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SampleLogFunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contour3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contour3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bananaFuncContour3.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kws&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.03&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kws&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;winter&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;scatter3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zcolumns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Banana Function Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ccolumns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Banana Function Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bananaFuncScatter3.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;bananaFuncContour3.png&quot; alt=&quot;bananaFuncContour3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;bananaFuncScatter3.png&quot; alt=&quot;bananaFuncScatter3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, this MCMC chain is a time-series data, meaning that we can compute its autocorrelation (for each data attribute). The ParaMonte library does this for us automatically which we can visualize via,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autocorr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autocorr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bananaCompactChainACF.png&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;bananaCompactChainACF.png&quot; alt=&quot;bananaCompactChainACF.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Obviously, the three attributes of this chain are autocorrelated. But, we can remove traces of autocorrelation by choosing an appropriate step by which we jump over (skip) the data to &lt;em&gt;thin&lt;/em&gt; (or &lt;em&gt;reduce&lt;/em&gt; or &lt;em&gt;decorrelate&lt;/em&gt; or &lt;em&gt;refine&lt;/em&gt; the chain).  Choose such an appropriate step size and refine the data in &lt;code&gt;chain.df&lt;/code&gt; and then compute the autocorrelation of the refined data via &lt;code&gt;scipy.signal.correlate&lt;/code&gt; function. Then, visualize it similar to the above illustration by the ParaMonte library to ensure the refinement process has truly removed the autocorrelation from your data.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy.signal&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correlate&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;attribute&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attribute&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;correlate &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attribute&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attribute&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;full&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;


  
  &lt;p&gt;&lt;a href=&quot;https://www.cdslab.org/recipes/programming/stat-autocorr-removal/stat-autocorr-removal&quot;&gt;Computing and removing the autocorrelation of a dataset&lt;/a&gt; was originally published by Amir Shahmoradi at &lt;a href=&quot;https://www.cdslab.org/recipes&quot;&gt;CDSLab Recipes - A repository for all sorts of problems with solutions&lt;/a&gt; on October 11, 2021.&lt;/p&gt;</content>
</entry>

</feed>
